{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_To do list_**\n",
    "# - Bifurcation analysis\n",
    "# - numerical method stability analysis\n",
    "# - numerical method accuracy analysis\n",
    "# - fractal dimension calculation\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _**The Lorenz System**_\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Abstract**\n",
    "This paper investigates the Lorenz system, a set of nonlinear differential equations that serve as a foundational model in the study of dynamical systems. Beginning with a discussion of the system's mathematical formulation and its physical origins in fluid convection, we explore the behavior of the system under varying parameter conditions. Through numerical simulations, we analyze key features such as equilibrium points, stability, and bifurcation phenomena, which reveal the system's transition between different dynamic regimes. Special attention is given to the emergence of chaos, highlighting the system's sensitivity to initial conditions and the underlying mechanisms that lead to unpredictable behavior. The study is supported by a series of plots and animations that visualize the system's trajectories, bifurcation diagrams, and phase space dynamics. These results provide both qualitative and quantitative insights into the Lorenz system, demonstrating its role as a rich and instructive example of nonlinear dynamics and chaos theory.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **History of the Lorenz System**\n",
    "\n",
    "In 1961, Edward Lorenz was using a Royal McBee LGP-30, a simple digital computer, to simulate weather patterns by modeling twelve variables such as temperature and wind speed. In an effort to save time, he decided to restart a simulation from a point in the middle of the data, using a printout that represented the conditions at that point. However, he was surprised to find that the weather predictions diverged significantly from the previous run. The reason for this discrepancy was a small error introduced by rounding: the computer worked with six-digit precision, but the printout rounded the variables to three digits. For example, a value like $0.506127$ was printed as $0.506$. While the difference appeared negligible, it led to drastically different results in the long-term simulation.\n",
    "\n",
    "Lorenz's discovery demonstrated that even small changes in initial conditions could result in significantly different outcomes over time, a phenomenon that later became central to chaos theory. His work, assisted by Ellen Fetter, culminated in his seminal 1963 paper, *Deterministic Nonperiodic Flow*, published in the *Journal of the Atmospheric Sciences*. In this paper, Lorenz laid the foundation for chaos theory, asserting:\n",
    "\n",
    "_\"Two states differing by imperceptible amounts may eventually evolve into two considerably different states ... If, then, there is any error whatever in observing the present state—and in any real system such errors seem inevitable—an acceptable prediction of an instantaneous state in the distant future may well be impossible. In view of the inevitable inaccuracy and incompleteness of weather observations, precise very-long-range forecasting would seem to be nonexistent.\"_\n",
    "\n",
    "Lorenz further developed the idea of the \"butterfly effect\" in 1969, illustrating how small changes in initial conditions could lead to large, unpredictable consequences. His work fundamentally reshaped our understanding of deterministic systems and weather forecasting, establishing that precise long-term predictions are inherently limited by the sensitivity of initial conditions.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "The Lorenz system consists of three coupled, nonlinear ordinary differential equations that model simplified fluid convection. Initially designed to investigate atmospheric processes, the system has since become a cornerstone in the study of nonlinear dynamics. It illustrates how deterministic systems, despite following fixed rules, can produce complex and unpredictable behavior. By analyzing the interactions between its variables, the Lorenz system highlights the sensitivity of dynamical systems to small changes in initial conditions. This paper explores the mathematical structure, key characteristics, and behaviors of the Lorenz system, emphasizing its relevance in the broader field of dynamical systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Equations**\n",
    "The equations governing the Lorenz system are: \n",
    " $$\\begin{cases} \\dot{x}​=σ(y−x), \\\\ \\dot{y}=x(ρ−z)−y, \\\\ \\dot{z}=xy−βz. \\end{cases}$$ \n",
    " Here $x$, $y$, and $z$ represent the system's state variables, and $\\sigma$, $\\rho$, and $\\beta$ are real positive parameters. Typically, $\\sigma$ represents the Prandtl number, $\\rho$ is the Rayleigh number, and $\\beta$ is a geometric factor.\n",
    "\n",
    " ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Equilibrium Points_**\n",
    "\n",
    "In the context of dynamical systems, **equilibrium points** (also known as critical points, fixed points, or stationary points) are defined as the points in the phase space where the system remains at rest if initially placed there. Mathematically, these are the solutions to the equation:\n",
    "\n",
    "$$\n",
    "\\dot{x} = f(x) = 0\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $x \\in \\mathbb{R}^n$: The state vector of the system.\n",
    "- $f(x)$: A vector-valued function that defines the dynamics of the system.\n",
    "- $\\dot{x}$: The time derivative of $x$.\n",
    "\n",
    "---\n",
    "\n",
    "### **Properties of Equilibrium Points**\n",
    "1. **Existence**: An equilibrium point $x^*$ exists if there is at least one solution to the equation $f(x^*) = 0$.\n",
    "2. **Stability**:\n",
    "   - **Stable (Lyapunov Stable)**: An equilibrium point $x^*$ is stable if, for every $\\epsilon > 0$, there exists a $\\delta > 0$ such that whenever $\\|x(0) - x^*\\| < \\delta$, it follows that $\\|x(t) - x^*\\| < \\epsilon$ for all $t \\geq 0$.\n",
    "   - **Asymptotically Stable**: An equilibrium point $x^*$ is asymptotically stable if it is stable and $\\|x(t) - x^*\\| \\to 0$ as $t \\to \\infty$.\n",
    "   - **Exponentially Stable**: An equilibrium point $x^*$ is exponentially stable if there exist constants $c > 0$ and $\\lambda > 0$ such that $\\|x(t) - x^*\\| \\leq c e^{-\\lambda t}$ for all $t \\geq 0$.\n",
    "   - **Unstable**: An equilibrium point $x^*$ is unstable if it is not stable.\n",
    "\n",
    "   ---\n",
    "\n",
    "\n",
    "### **Classification of Equilibrium Points**\n",
    "Equilibrium points can be classified based on the behavior of the system near these points. This is typically analyzed using techniques such as:\n",
    "\n",
    "- **Linearization**: Approximating $f(x)$ near $x^*$ by its Jacobian $\\mathbf{J} = \\frac{\\partial f}{\\partial x} \\big|_{x^*}$. The eigenvalues of $\\mathbf{J}$ determine the local behavior.\n",
    "- **Nonlinear Analysis**: Using Lyapunov functions or other methods for systems where linearization is insufficient.\n",
    "\n",
    "Equilibrium points provide critical insights into the qualitative behavior of dynamical systems and their long-term evolution.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculating Equilibrium Points**\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\dot{x} = \\sigma (y - x) = 0, \\\\\n",
    "\\dot{y} = x(\\rho - z) - y = 0, \\\\\n",
    "\\dot{z} = xy - \\beta z = 0; \\\\\n",
    "\\end{cases}\n",
    "\\implies\n",
    "\\begin{cases}\n",
    "x = y, \\\\\n",
    "x = \\pm \\sqrt{\\beta z}, \\\\\n",
    "x (\\rho - z - 1) = 0; \\\\\n",
    "\\end{cases}\n",
    "\\implies\n",
    "\\begin{cases}\n",
    "x^*_1 = (0, 0, 0), \\\\\n",
    "x^*_2 = (\\sqrt{\\beta (\\rho - 1)}, \\; \\sqrt{\\beta (\\rho - 1)}, \\; \\rho - 1), \\quad \\rho \\geq 1; \\\\\n",
    "x^*_3 = (-\\sqrt{\\beta (\\rho - 1)}, \\; -\\sqrt{\\beta (\\rho - 1)}, \\; \\rho - 1), \\quad \\rho \\geq 1. \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Calculating the Stability of Equilibrium Points**\n",
    "The Jacobian matrix $\\mathbf{J}$ is given by:\n",
    "$$\n",
    "\\mathbf{J} = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial \\dot{x}}{\\partial x} & \\frac{\\partial \\dot{x}}{\\partial y} & \\frac{\\partial \\dot{x}}{\\partial z} \\\\\n",
    "\\frac{\\partial \\dot{y}}{\\partial x} & \\frac{\\partial \\dot{y}}{\\partial y} & \\frac{\\partial \\dot{y}}{\\partial z} \\\\\n",
    "\\frac{\\partial \\dot{z}}{\\partial x} & \\frac{\\partial \\dot{z}}{\\partial y} & \\frac{\\partial \\dot{z}}{\\partial z}\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "-\\sigma & \\sigma & 0 \\\\\n",
    "\\rho - z & -1 & -x \\\\\n",
    "y & x & -\\beta\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### **Stability of $x^*_1 = (0, 0, 0)$:**\n",
    "\n",
    "At $x^*_1 = (0, 0, 0)$, the Jacobian matrix is:\n",
    "$$\n",
    "\\mathbf{J}(0, 0, 0) = \n",
    "\\begin{bmatrix}\n",
    "-\\sigma & \\sigma & 0 \\\\\n",
    "\\rho & -1 & 0 \\\\\n",
    "0 & 0 & -\\beta\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The characteristic equation is:\n",
    "$$\n",
    "\\text{det}(\\mathbf{J} - \\lambda \\mathbf{I}) = \n",
    "\\text{det} \\left( \n",
    "\\begin{bmatrix}\n",
    "-\\sigma - \\lambda & \\sigma & 0 \\\\\n",
    "\\rho & -1 - \\lambda & 0 \\\\\n",
    "0 & 0 & -\\beta - \\lambda\n",
    "\\end{bmatrix}\n",
    "\\right) = 0\n",
    "$$\n",
    "\n",
    "Now, calculate the determinant:\n",
    "$$\n",
    "\\text{det} \\left( \n",
    "\\begin{bmatrix}\n",
    "-\\sigma - \\lambda & \\sigma & 0 \\\\\n",
    "\\rho & -1 - \\lambda & 0 \\\\\n",
    "0 & 0 & -\\beta - \\lambda\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "= (-\\beta - \\lambda) \\cdot \\text{det} \\begin{bmatrix} -\\sigma - \\lambda & \\sigma \\\\ \\rho & -1 - \\lambda \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Thus, the characteristic equation becomes:\n",
    "$$\n",
    "(\\lambda + \\beta)(\\lambda^2 + (\\sigma + 1)\\lambda + (\\sigma - \\sigma \\rho)) = 0\n",
    "$$\n",
    "\n",
    "The solutions are:\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\lambda_1 = -\\beta, \\quad \\text{(negative)}; \\\\\n",
    "\\lambda_2 = \\frac{-(\\sigma + 1) - \\sqrt{(\\sigma + 1)^2 - 4(\\sigma - \\sigma \\rho)}}{2}, \\quad \\text{(negative)}; \\\\\n",
    "\\lambda_3 = \\frac{-(\\sigma + 1) + \\sqrt{(\\sigma + 1)^2 - 4(\\sigma - \\sigma \\rho)}}{2}, \\quad \\text{(negative for }\\rho < 1, \\text{ positive for } \\rho > 1); \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Thus, the point $x^*_1 = (0, 0, 0)$ is stable for $\\rho < 1$ and unstable for $\\rho > 1$.\n",
    "\n",
    "---\n",
    "\n",
    "### **Stability of $x^*_2 = (\\sqrt{\\beta (\\rho - 1)}, \\; \\sqrt{\\beta (\\rho - 1)}, \\; \\rho - 1)$, for $\\rho \\geq 1$:**\n",
    "\n",
    "We first calculate the Jacobian matrix $\\mathbf{J}$ at $x^*_2$:\n",
    "$$\n",
    "\\mathbf{J} = \n",
    "\\begin{bmatrix}\n",
    "-\\sigma & \\sigma & 0 \\\\\n",
    "\\rho - z & -1 & -x \\\\\n",
    "y & x & -\\beta\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "At $x^*_2 = (\\sqrt{\\beta (\\rho - 1)}, \\; \\sqrt{\\beta (\\rho - 1)}, \\; \\rho - 1)$, the Jacobian matrix becomes:\n",
    "$$\n",
    "\\mathbf{J}(x^*_2) = \n",
    "\\begin{bmatrix}\n",
    "-\\sigma & \\sigma & 0 \\\\\n",
    "\\rho - (\\rho - 1) & -1 & -\\sqrt{\\beta (\\rho - 1)} \\\\\n",
    "\\sqrt{\\beta (\\rho - 1)} & \\sqrt{\\beta (\\rho - 1)} & -\\beta\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "-\\sigma & \\sigma & 0 \\\\\n",
    "1 & -1 & -\\sqrt{\\beta (\\rho - 1)} \\\\\n",
    "\\sqrt{\\beta (\\rho - 1)} & \\sqrt{\\beta (\\rho - 1)} & -\\beta\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The characteristic equation for the Jacobian is:\n",
    "$$\n",
    "\\text{det}(\\mathbf{J} - \\lambda \\mathbf{I}) = 0\n",
    "$$\n",
    "\n",
    "Now, calculate the determinant of the matrix:\n",
    "$$\n",
    "\\text{det} \\left( \n",
    "\\begin{bmatrix}\n",
    "-\\sigma - \\lambda & \\sigma & 0 \\\\\n",
    "1 & -1 - \\lambda & -\\sqrt{\\beta (\\rho - 1)} \\\\\n",
    "\\sqrt{\\beta (\\rho - 1)} & \\sqrt{\\beta (\\rho - 1)} & -\\beta - \\lambda\n",
    "\\end{bmatrix}\n",
    "\\right) = 0\n",
    "$$\n",
    "\n",
    "Solving this determinant yields the characteristic polynomial:\n",
    "$$\n",
    "(\\lambda + \\beta)(\\lambda^2 + (\\sigma + 1)\\lambda + (\\sigma - \\sigma \\rho - \\sqrt{\\beta (\\rho - 1)})) = 0\n",
    "$$\n",
    "\n",
    "For $\\rho \\geq 1$, the stability of $x^*_2$ depends on the signs of the eigenvalues:\n",
    "- The equilibrium point is stable if the real parts of all eigenvalues are negative.\n",
    "- The equilibrium point is unstable if any eigenvalue has a positive real part.\n",
    "\n",
    "---\n",
    "\n",
    "### **Stability of $x^*_3 = (-\\sqrt{\\beta (\\rho - 1)}, \\; -\\sqrt{\\beta (\\rho - 1)}, \\; \\rho - 1)$, for $\\rho \\geq 1$:**\n",
    "\n",
    "Next, we calculate the Jacobian matrix at $x^*_3 = (-\\sqrt{\\beta (\\rho - 1)}, \\; -\\sqrt{\\beta (\\rho - 1)}, \\; \\rho - 1)$:\n",
    "\n",
    "$$\n",
    "\\mathbf{J}(x^*_3) = \n",
    "\\begin{bmatrix}\n",
    "-\\sigma & \\sigma & 0 \\\\\n",
    "\\rho - z & -1 & -x \\\\\n",
    "y & x & -\\beta\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "At $x^*_3 = (-\\sqrt{\\beta (\\rho - 1)}, \\; -\\sqrt{\\beta (\\rho - 1)}, \\; \\rho - 1)$, the Jacobian matrix becomes:\n",
    "$$\n",
    "\\mathbf{J}(x^*_3) = \n",
    "\\begin{bmatrix}\n",
    "-\\sigma & \\sigma & 0 \\\\\n",
    "\\rho - (\\rho - 1) & -1 & \\sqrt{\\beta (\\rho - 1)} \\\\\n",
    "-\\sqrt{\\beta (\\rho - 1)} & -\\sqrt{\\beta (\\rho - 1)} & -\\beta\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "-\\sigma & \\sigma & 0 \\\\\n",
    "1 & -1 & \\sqrt{\\beta (\\rho - 1)} \\\\\n",
    "-\\sqrt{\\beta (\\rho - 1)} & -\\sqrt{\\beta (\\rho - 1)} & -\\beta\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The characteristic equation is again:\n",
    "$$\n",
    "\\text{det}(\\mathbf{J} - \\lambda \\mathbf{I}) = 0\n",
    "$$\n",
    "\n",
    "Now, solving the determinant yields the characteristic polynomial:\n",
    "$$\n",
    "(\\lambda + \\beta)(\\lambda^2 + (\\sigma + 1)\\lambda + (\\sigma - \\sigma \\rho - \\sqrt{\\beta (\\rho - 1)})) = 0\n",
    "$$\n",
    "\n",
    "For $\\rho \\geq 1$, the equilibrium point $x^*_3$ is stable if all eigenvalues have negative real parts and unstable if any eigenvalue has a positive real part.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion:**\n",
    "- For $x^*_1 = (0, 0, 0)$, the stability is dependent on $\\rho$. It is stable for $\\rho < 1$ and unstable for $\\rho > 1$.\n",
    "- For $x^*_2 = (\\sqrt{\\beta (\\rho - 1)}, \\; \\sqrt{\\beta (\\rho - 1)}, \\; \\rho - 1)$, the stability depends on the eigenvalues, and it is stable if all eigenvalues have negative real parts.\n",
    "- For $x^*_3 = (-\\sqrt{\\beta (\\rho - 1)}, \\; -\\sqrt{\\beta (\\rho - 1)}, \\; \\rho - 1)$, the stability is similar to $x^*_2$.\n",
    "\n",
    "---\n",
    "\n",
    "This solution provides all the calculations, eigenvalue solutions, and stability conditions for each equilibrium point in the system. Let me know if any further modifications are needed!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Definitions**\n",
    "Before we get to the fun stuff, we need to lay down some definitions.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Dynamical Systems_**\n",
    "---\n",
    "\n",
    "A **dynamical system** is a mathematical formulation used to describe the time-dependent evolution of a point in a geometrical space. It consists of a set of rules or equations that dictate how the state of the system evolves over time. The state of a dynamical system is represented by a point in a state space, and its evolution is described by a trajectory or orbit within this space.\n",
    "\n",
    "A dynamical system can be formally defined as a pair $(T, \\varphi)$, where:\n",
    "- $T$ represents time, which may be discrete (e.g., $T = \\mathbb{Z}$) or continuous (e.g., $T = \\mathbb{R}$),\n",
    "- $\\varphi: T \\times X \\to X$ is a function that describes the system's evolution, where $X$ is the state space.\n",
    "\n",
    "For discrete-time dynamical systems, the evolution is governed by difference equations:\n",
    "$$ x_{n+1} = f(x_n, n), $$\n",
    "where $x_n \\in X$ denotes the state at time step $n$, and $f: X \\times \\mathbb{Z} \\to X$ is a function that determines the evolution.\n",
    "\n",
    "For continuous-time dynamical systems, the evolution is governed by differential equations:\n",
    "$$ \\dot{x} = f(x, t), $$\n",
    "where $x \\in X$ represents the state vector, $t \\in T$ represents time, and $f: X \\times T \\to X$ is a vector field governing the evolution.\n",
    "\n",
    "This document primarily focuses on continuous-time dynamical systems.\n",
    "\n",
    "---\n",
    "\n",
    "#### **State Space**\n",
    "The **state space** $X$ is the set of all possible states of the system. In the case of a system describing, for instance, the position and velocity of a moving object, the state space encompasses all possible combinations of position and velocity. For systems governed by ordinary differential equations (ODEs), the state space is typically a vector space or manifold, where each point represents a distinct state of the system.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Trajectory**\n",
    "A **trajectory** (or orbit) of a dynamical system is the path traced by the system as it evolves over time. For a given system of ODEs, this trajectory corresponds to the solution curve of the differential equation:\n",
    "$$ \\dot{x}(t) = f(x(t)), $$\n",
    "where $x(t)$ represents the state of the system at time $t$.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Flow of a System**\n",
    "The **flow** of a dynamical system, denoted by $\\varphi_t(x_0)$, represents the evolution of an initial state $x_0$ under the system's governing dynamics. The flow provides the trajectory of $x_0$ as time progresses:\n",
    "$$ \\varphi_t(x_0) = x(t), $$\n",
    "where $x_0$ is the initial condition and $x(t)$ is the state of the system at time $t$.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **Fixed Point**\n",
    "A **fixed point** $x^*$ (or equilibrium point) is a state where the system remains unchanged. Mathematically, a fixed point satisfies:\n",
    "$$ \\dot{x}(t) = f(x^*) = 0, $$\n",
    "indicating that the system does not evolve when it is at $x^*$. The stability of a fixed point is determined by the Jacobian matrix $J = Df(x^*)$ evaluated at the fixed point.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Stability of Fixed Points**\n",
    "The **stability** of a fixed point depends on the eigenvalues of the Jacobian matrix $J$. If the real parts of all eigenvalues of $J$ are negative, the fixed point is **stable**, meaning that small perturbations will decay over time. Conversely, if any eigenvalue has a positive real part, the fixed point is **unstable**, meaning that perturbations will grow over time.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Linearization**\n",
    "**Linearization** refers to approximating a nonlinear system by a linear system near a specific point of interest, typically a fixed point or periodic orbit. In the context of ODEs, linearization around a point involves computing the Jacobian matrix of the system at that point. This matrix characterizes the behavior of small perturbations near the point of interest.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Jacobian Matrix**\n",
    "The **Jacobian matrix** $J = Df(x)$ is a matrix of partial derivatives that describes the local behavior of the system around a point. It is used to analyze stability:\n",
    "$$ J_{ij} = \\frac{\\partial f_i}{\\partial x_j}, $$\n",
    "where $f_i$ is the $i$-th component of the system's vector field $f(x)$.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Eigenvalues of the Jacobian**\n",
    "The **eigenvalues** of the Jacobian matrix play a central role in determining the stability of a fixed point. If all eigenvalues have negative real parts, the fixed point is stable. If any eigenvalue has a positive real part, the fixed point is unstable.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **Periodic Trajectories**\n",
    "A **periodic trajectory** $\\gamma(t)$ of a dynamical system is a solution to the differential equation\n",
    "$$ \\dot{x}(t) = f(x(t)), $$\n",
    "such that $\\gamma(t + T) = \\gamma(t)$ for some period $T > 0$ and for all $t$. This implies that the trajectory repeats itself after time $T$.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Linearization Around a Trajectory**\n",
    "To analyze the behavior of small perturbations near a periodic trajectory, we linearize the system. Let $x(t) = \\gamma(t) + \\xi(t)$, where $\\xi(t)$ represents a small deviation from the periodic orbit. Substituting this into the system and neglecting higher-order terms in $\\xi(t)$ results in the **variational equation**:\n",
    "$$ \\dot{\\xi}(t) = \\frac{\\partial f}{\\partial x} \\big|_{\\gamma(t)} \\xi(t), $$\n",
    "where $\\frac{\\partial f}{\\partial x} \\big|_{\\gamma(t)}$ is the Jacobian matrix of $f(x)$ evaluated along the periodic trajectory $\\gamma(t)$.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Fundamental Matrix Solution**\n",
    "A **fundamental matrix solution** $\\Xi(t)$ of the variational equation satisfies:\n",
    "$$ \\dot{\\Xi}(t) = \\frac{\\partial f}{\\partial x} \\big|_{\\gamma(t)} \\Xi(t), $$\n",
    "with the initial condition $\\Xi(0) = I$, where $I$ is the identity matrix. The columns of $\\Xi(t)$ represent independent solutions to the variational equation.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Monodromy Matrix**\n",
    "The **monodromy matrix** $\\Phi(T)$ describes the evolution of perturbations over one period $T$ of the periodic trajectory. It is given by:\n",
    "$$ \\Phi(T) = \\Xi(T), $$\n",
    "where $\\Xi(T)$ is the fundamental matrix evaluated at time $t = T$. This matrix encapsulates the behavior of small deviations after one complete cycle of the periodic trajectory.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Floquet Multipliers**\n",
    "The **Floquet multipliers** are the eigenvalues of the monodromy matrix $\\Phi(T)$. These eigenvalues provide insight into the stability of the periodic trajectory:\n",
    "1. If all Floquet multipliers, except for the trivial one $\\lambda = 1$, have magnitudes less than $1$, the periodic orbit is **stable**.\n",
    "2. If any Floquet multiplier has a magnitude greater than or equal to $1$ (other than $\\lambda = 1$), the periodic orbit is **unstable**.\n",
    "\n",
    " **Additional Notes**\n",
    "1. The trivial Floquet multiplier $\\lambda = 1$ exists because perturbations along the periodic trajectory do not grow or decay, reflecting its periodic nature.\n",
    "2. These concepts are widely employed in the analysis of oscillatory phenomena in systems such as mechanical vibrations, electrical circuits, and biological rhythms.\n",
    "\n",
    "\n",
    "---\n",
    " \n",
    "#### **Lyapunov Exponent**\n",
    "\n",
    "The Lyapunov exponent is a measure used to characterize the rate of separation of infinitesimally close trajectories in a dynamical system. It quantifies the sensitivity to initial conditions. Formally, the largest Lyapunov exponent $\\lambda_1$ is defined as:\n",
    "\n",
    "$$\n",
    "\\lambda_1 = \\lim_{t \\to \\infty} \\lim_{\\delta x(0) \\to 0} \\frac{1}{t} \\ln \\frac{|\\delta x(t)|}{|\\delta x(0)|}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\delta x(0)$ is the initial separation between two trajectories.\n",
    "- $\\delta x(t)$ is the separation at time $t$.\n",
    "\n",
    "\n",
    "The Lyapunov exponents $\\lambda_i$ are ordered such that $\\lambda_1 \\geq \\lambda_2 \\geq \\dots \\geq \\lambda_n$. \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Chaotic Behavior**\n",
    "**Chaos** refers to complex, seemingly unpredictable behavior in a dynamical system, despite the system being deterministic (i.e., governed by specific rules). A chaotic system typically exhibits sensitive dependence on initial conditions, meaning that small changes in initial conditions lead to vastly different outcomes. This is often characterized by a positive **Lyapunov exponent** $\\lambda_1 > 0$, which indicates exponential divergence of nearby trajectories.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Fractal Dimension**\n",
    "The **fractal dimension** $d_H$ of an attractor is a measure of its complexity, indicating how it fills the state space. For a **strange attractor**, the Hausdorff dimension $d_H$ exceeds the topological dimension, indicating that the attractor has a highly intricate and irregular structure.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Topological Mixing**\n",
    "A system is said to exhibit **topological mixing** if, for any two open sets $U$ and $V$ on the attractor, there exists a time $T$ such that the trajectory of any point in $U$ will eventually enter $V$. This property suggests that the system's dynamics are sufficiently complex to explore the entire attractor.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Ergodic Theory**\n",
    "In ergodic theory, an **ergodic system** is one in which the long-term time averages of a trajectory coincide with averages taken over the entire state space (with respect to some invariant measure). This property is particularly relevant for chaotic systems, where trajectories are dense in the attractor and exhibit statistical properties.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **_Attractors_**\n",
    "\n",
    "\n",
    "In the context of dynamical systems, an attractor is a subset $A$ of the phase space $X$ toward which the system evolves over time. Formally, an attractor satisfies the following conditions:\n",
    "1. **Invariance**: $\\varphi_t(A) = A$, where $\\varphi_t$ is the evolution map of the dynamical system.\n",
    "2. **Attractiveness**: There exists a neighborhood $U \\subseteq X$ of $A$ such that for all $x \\in U$, $\\lim_{t \\to \\infty} \\text{dist}(\\varphi_t(x), A) = 0$.\n",
    "3. **Minimality**: No proper subset of $A$ satisfies the above conditions.\n",
    "\n",
    "Attractors can take various forms, including fixed points, periodic orbits, quasi-periodic tori, and more complex sets like strange attractors.\n",
    " \n",
    "---\n",
    "\n",
    "\n",
    "### **Types of Attractors**\n",
    "\n",
    "Attractors in dynamical systems can exhibit diverse behaviors, ranging from stable fixed points to chaotic strange attractors. Below are some common types of attractors.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Fixed Point Attractor**\n",
    "A fixed point $x^*$ satisfies $\\varphi_t(x^*) = x^*$ for all $t \\geq 0$. Stability is determined by the eigenvalues of the Jacobian matrix $J = Df(x^*)$, where $f$ is the system's flow:\n",
    "- If all eigenvalues have negative real parts, $x^*$ is a stable attractor.\n",
    "- **Example**: A damped pendulum at rest.\n",
    "\n",
    "---\n",
    " \n",
    "#### 2. **Limit Cycle Attractor**\n",
    "A periodic trajectory $\\gamma(t)$ satisfies $\\gamma(t + T) = \\gamma(t)$ for all $t$, with period $T > 0$. Stability depends on the Floquet multipliers derived from the monodromy matrix:\n",
    "- If all Floquet multipliers (except one with value $1$) have magnitudes less than $1$, the cycle is stable.\n",
    "- **Example**: Van der Pol oscillator.\n",
    "\n",
    "---\n",
    " \n",
    "#### 3. **Torus Attractor**\n",
    "A toroidal attractor corresponds to quasi-periodic motion  (quasi-periodic motion is motion on a torus that never comes back to the same point), typically arising from incommensurate frequencies $\\omega_1, \\omega_2, \\dots, \\omega_n$. The trajectory is given by:\n",
    "$$\n",
    "\\theta_i(t) = \\theta_i(0) + \\omega_i t \\mod 2\\pi,\n",
    "$$\n",
    "for $i = 1, \\dots, n$.\n",
    "- **Example**: Coupled oscillators.\n",
    "---\n",
    "\n",
    "#### 4. **Strange Attractor**\n",
    "\n",
    " \n",
    " Strange attractors exhibit fractal structures and chaotic behavior, where trajectories never settle to a point or cycle. These attractors are often found in nonlinear systems. However, before we define strange attractors, let's first introduce the concept of a Lyapunov exponent.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Mathematical Properties of Strange Attractors**\n",
    "\n",
    "Strange attractors possess the following defining characteristics:\n",
    "\n",
    "1. **Fractal Geometry**:  \n",
    "   The Hausdorff dimension $d_H$ of a strange attractor satisfies $d_H > \\text{topological dimension}$. This can be computed using the Lyapunov exponents $\\lambda_i$ through the Kaplan-Yorke formula:\n",
    "   $$\n",
    "   d_{KY} = k + \\frac{\\sum_{i=1}^k \\lambda_i}{|\\lambda_{k+1}|},\n",
    "   $$\n",
    "   where $k$ is the largest integer such that $\\sum_{i=1}^k \\lambda_i \\geq 0$.\n",
    "\n",
    "2. **Sensitive Dependence on Initial Conditions**:  \n",
    "   For two initial points $x_0$ and $\\tilde{x}_0$, the separation $|\\varphi_t(x_0) - \\varphi_t(\\tilde{x}_0)|$ grows exponentially:\n",
    "   $$\n",
    "   |\\varphi_t(x_0) - \\varphi_t(\\tilde{x}_0)| \\sim e^{\\lambda_1 t},\n",
    "   $$\n",
    "   where $\\lambda_1 > 0$ is the largest Lyapunov exponent.\n",
    "\n",
    "3. **Topological Mixing**:  \n",
    "   For any two open sets $U, V \\subseteq A$, there exists a $T > 0$ such that for all $t \\geq T$, $\\varphi_t(U) \\cap V \\neq \\emptyset$. This implies trajectories thoroughly explore the attractor.\n",
    "\n",
    "4. **Dense Periodic Orbits**:  \n",
    "   The attractor contains periodic points $x_p$ that are dense, ensuring any point on the attractor is arbitrarily close to a periodic orbit.\n",
    "\n",
    "---\n",
    "\n",
    "### **Chaotic Attractors**\n",
    "\n",
    "Chaotic attractors are a subclass of strange attractors where chaotic behavior is rigorously defined. For a dynamical system with a chaotic attractor, the following hold:\n",
    "1. **Positive Largest Lyapunov Exponent**:  \n",
    "   A positive Lyapunov exponent $\\lambda_1 > 0$ indicates exponential divergence of nearby trajectories.\n",
    "\n",
    "2. **Invariant Measures**:  \n",
    "   There exists an invariant measure $\\mu$ supported on the attractor, allowing for statistical properties to be studied. The ergodic nature ensures long-term averages are well-defined.\n",
    "\n",
    "3. **Deterministic Chaos**:  \n",
    "   The system's equations are deterministic, yet trajectories appear random due to sensitive dependence.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **_Theorem (Necessary and Sufficient Argument for Chaos)_**\n",
    "A strange attractor is considered chaotic $\\iff \\lambda_1 > 0$.\n",
    "\n",
    "---\n",
    "\n",
    "### **_Theorem (Divergence of Chaotic Systems)_**\n",
    "\n",
    "Let $\\mathcal{M}$ be a differentiable manifold and $f: \\mathcal{M} \\rightarrow \\mathcal{M}$ be a smooth dynamical system. For a trajectory starting at $x_0 \\in \\mathcal{M}$, the Lyapunov exponent $\\lambda$ characterizes the rate of separation of infinitesimally close trajectories.\n",
    "\n",
    "\n",
    "\n",
    "**Definition:** For two trajectories initially separated by a small perturbation $\\delta Z_0$, their separation $\\delta Z(t)$ at time $t$ evolves according to\n",
    "\n",
    "$$|\\delta Z(t)| \\approx e^{\\lambda t}|\\delta Z_0|.$$\n",
    "\n",
    "\n",
    "\n",
    "**Properties:**\n",
    "1. The spectrum of Lyapunov exponents $\\{\\lambda_i\\}$ has dimension equal to $\\dim(\\mathcal{M})$\n",
    "2. Each $\\lambda_i$ measures the exponential divergence rate in a particular direction\n",
    "3. The maximal Lyapunov exponent (MLE) governs the system's predictability\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Theorem (Divergence of Chaotic Systems)_**\n",
    "\n",
    "Let $\\mathcal{M}$ be a differentiable manifold and $f: \\mathcal{M} \\rightarrow \\mathcal{M}$ be a smooth dynamical system. For a trajectory starting at $x_0 \\in \\mathcal{M}$, the Lyapunov exponent $\\lambda$ characterizes the rate of separation of infinitesimally close trajectories.\n",
    "\n",
    "**Definition:** For two trajectories initially separated by a small perturbation $\\delta Z_0$, their separation $\\delta Z(t)$ at time $t$ evolves according to\n",
    "\n",
    "$$|\\delta Z(t)| \\approx e^{\\lambda t}|\\delta Z_0|.$$\n",
    "\n",
    "**Properties:**\n",
    "1. The spectrum of Lyapunov exponents $\\{\\lambda_i\\}$ has dimension equal to $\\dim(\\mathcal{M})$\n",
    "2. Each $\\lambda_i$ measures the exponential divergence rate in a particular direction\n",
    "3. The maximal Lyapunov exponent (MLE) governs the system's predictability\n",
    "\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## _**The Lorenz Attractor**_\n",
    "\n",
    "The Lorenz attractor is a set of chaotic solutions to the Lorenz system. The system exhibits sensitive dependence on initial conditions, which is a hallmark of chaotic behavior. It emegres from the parameters $\\sigma = 10$, $\\rho = 28$, and $\\beta = \\frac83$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis venenatis nulla feugiat quam vulputate, ut ultricies neque pulvinar. Suspendisse dictum nunc tincidunt lacus elementum, eu lacinia odio cursus. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aliquam eget tincidunt eros, non posuere mi. Morbi ut tempor elit. Aliquam quis nibh ut ipsum condimentum sollicitudin sit amet ac est. Ut efficitur lacus sit amet augue malesuada aliquam. Sed in quam commodo, eleifend ex sit amet, tempus eros. Morbi imperdiet ipsum augue, nec porta sapien vestibulum laoreet.\n",
    "\n",
    "Suspendisse vel blandit dui, a eleifend libero. Curabitur maximus metus vel sapien rutrum, vulputate iaculis ante tincidunt. Praesent sit amet finibus diam. Mauris tincidunt pretium sagittis. Sed cursus est a blandit ullamcorper. Sed tempor velit nec neque maximus molestie. Aliquam nec ante nec nunc convallis dictum id nec ligula. Etiam mollis bibendum nunc sit amet bibendum.\n",
    "\n",
    "Quisque fringilla sagittis magna et luctus. Integer condimentum feugiat erat at dignissim. Phasellus vulputate consequat enim, et luctus velit semper at. Mauris sed elit mattis, commodo tellus sagittis, feugiat sem. Pellentesque egestas vel justo pellentesque consectetur. Duis eleifend consequat bibendum. Donec dapibus mollis lectus, sit amet ultricies leo consequat vitae. Quisque non velit at erat sollicitudin congue eget commodo ipsum. Praesent eget auctor erat, sit amet commodo ante. Ut at augue dui. Vivamus et libero tincidunt, pharetra arcu ut, mattis mauris. Integer ultricies, augue eget vulputate feugiat, nunc lorem tempus libero, vitae placerat nunc ligula vitae neque. Curabitur vel augue semper, interdum neque vel, consectetur massa. Duis placerat volutpat tincidunt. Quisque placerat, lorem nec hendrerit auctor, felis eros molestie ex, iaculis aliquam eros lacus vitae sem.\n",
    "\n",
    "Curabitur condimentum accumsan lacus sit amet rhoncus. Nam sed mattis nisl, sit amet finibus orci. Ut nunc ipsum, fermentum ac rutrum eu, scelerisque consectetur dui. Suspendisse nulla velit, ullamcorper vehicula metus sed, semper mollis diam. In hac habitasse platea dictumst. Aenean tincidunt vulputate egestas. Fusce consectetur erat ac leo vulputate, id finibus eros vulputate. Vivamus finibus tristique pharetra. Nunc feugiat purus feugiat augue blandit porta. Fusce vulputate nec leo non accumsan. Morbi a orci dui. Ut ac dapibus elit, at molestie sapien. Nunc porta pharetra nunc, vel blandit sapien dapibus id.\n",
    "\n",
    "Praesent ornare sagittis ligula, at fermentum lacus molestie ac. Aenean et mollis tellus. Nam sit amet diam nisl. Suspendisse velit dui, mattis eget purus rutrum, pretium maximus arcu. Vestibulum volutpat consectetur fermentum. Integer tempus, augue id aliquam suscipit, tellus ex scelerisque risus, ut posuere ante augue non ligula. Nulla ut nisl nec nunc auctor egestas at nec metus. In hac habitasse platea dictumst.\n",
    "\n",
    "Vestibulum id dignissim ligula. In hac habitasse platea dictumst. Fusce vitae lacus vehicula nunc venenatis tincidunt eu et ipsum. In scelerisque nunc leo, eget placerat ipsum viverra volutpat. Nulla ut faucibus ante, nec accumsan libero. Cras quam lectus, aliquam non nisl quis, sodales hendrerit nunc. Suspendisse consequat tellus vel urna lacinia aliquet ut ac turpis. Maecenas eleifend neque a vestibulum imperdiet. Pellentesque pharetra augue lorem, id varius velit pellentesque eget. Donec eget ullamcorper ligula. \n",
    "\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Numerical Methods for Solving Systems of Ordinary Differential Equations_**\n",
    "\n",
    "Ordinary differential equations frequently arise in scientific and engineering contexts, where they model the dynamic behavior of systems over time or space. While some ordinary differential equations have exact analytical solutions, many do not, requiring the use of **numerical methods** to obtain approximate solutions.\n",
    " \n",
    "---\n",
    "\n",
    "#### **Core Aspects of Numerical Methods**\n",
    "\n",
    "- **Discrete Computation**: Numerical methods solve ordinary differential equations by evaluating solutions at discrete points, rather than providing a continuous exact solution.\n",
    "- **Trade-off between Simplicity and Accuracy**: \n",
    "  - Simpler methods, such as Euler's method, are easy to implement but often require smaller time steps to achieve acceptable accuracy.\n",
    "  - More advanced methods, such as the Runge-Kutta method or implicit schemes, offer higher accuracy with fewer steps but involve more complex computations.\n",
    " \n",
    "---\n",
    "\n",
    "#### **Objective of This Section**\n",
    "\n",
    "The purpose of this section is to explore practical numerical approaches for solving systems of ordinary differential equations, particularly when exact solutions are not available. The focus is on methods that effectively balance ease of implementation with computational accuracy, ensuring both accessibility and the capability to solve complex systems.\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_The Lorenz System in Python code_**\n",
    "\n",
    "For implementing ODEs in Python, we define a function that returns the derivatives of the state variables at a given time. We then use a numerical solver, whitch we will define in a momment, to integrate the system forward in time. The following code snippet demonstrates the implementation of the Lorenz system in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def lorenz(t, state, sigma, rho, beta):\n",
    "    x, y, z = state\n",
    "    dxdt = sigma * (y - x)\n",
    "    dydt = x * (rho - z) - y\n",
    "    dzdt = x * y - beta * z\n",
    "    return np.array([dxdt, dydt, dzdt])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Forward Euler Method**\n",
    "\n",
    "The **Forward Euler method** is a simple numerical technique for solving systems of ordinary differential equations. It is an explicit method that calculates the solution at the next time step using the values and derivatives at the current time step.\n",
    "\n",
    "#### **Formula**\n",
    "\n",
    "Consider a system of differential equations of the form:\n",
    "\n",
    "$$ \\frac{d\\mathbf{y}}{dt} = \\mathbf{f}(t, \\mathbf{y}), \\quad \\mathbf{y}(t_0) = \\mathbf{y_0} $$\n",
    "\n",
    "where:\n",
    "\n",
    "The Forward Euler method approximates the solution for each component of the system as:\n",
    "\n",
    "$$ \\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\cdot \\mathbf{f}(t_n, \\mathbf{y}_n) $$\n",
    "\n",
    "where:\n",
    "- $ \\mathbf{y}_n $ is the vector of solutions at the current step,\n",
    "- $ h $ is the step size,\n",
    "- $ \\mathbf{f}(t_n, \\mathbf{y}_n) $ is the vector of derivatives evaluated at $ t_n $.\n",
    "\n",
    "#### **Characteristics**\n",
    "\n",
    "- **Simplicity**: The method is straightforward to implement and easy to understand.\n",
    "- **Accuracy**: It is a first-order method, meaning the error decreases linearly with the step size.\n",
    "- **Limitations**: The method requires small step sizes to maintain stability and accuracy, especially for stiff systems.\n",
    "\n",
    "The Forward Euler method is a useful starting point for solving systems of ordinary differential equations but may not be suitable for all problems due to its limited stability range.\n",
    "\n",
    "Below, we implement the Forward Euler method for systems in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_euler(f, initial_state, t0, tf, dt, args):\n",
    "    def f_(t,state, args=args):\n",
    "        return f(t, state, *args)\n",
    "    t = np.arange(t0, tf, dt)\n",
    "    n = len(t)\n",
    "    states = np.zeros((n, len(initial_state)))\n",
    "    states[0] = initial_state\n",
    "    for i in range(n - 1):\n",
    "        states[i + 1] = states[i] + dt * f_(t[i], states[i])\n",
    "    return states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Backward Euler Method**\n",
    "\n",
    "The **Backward Euler method** is an implicit numerical technique for solving systems of ordinary differential equations. Unlike the Forward Euler method, it calculates the solution at the next time step using the values and derivatives at the next time step, requiring the solution of an equation at each step.\n",
    "\n",
    "#### **Formula**\n",
    "\n",
    "Consider a system of differential equations of the form:\n",
    "\n",
    "$$ \\frac{d\\mathbf{y}}{dt} = \\mathbf{f}(t, \\mathbf{y}), \\quad \\mathbf{y}(t_0) = \\mathbf{y_0} $$\n",
    "\n",
    "The Backward Euler method approximates the solution for each component of the system as:\n",
    "\n",
    "$$ \\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\cdot \\mathbf{f}(t_{n+1}, \\mathbf{y}_{n+1}) $$\n",
    "\n",
    "where:\n",
    "- $ \\mathbf{y}_n $ is the vector of solutions at the current step,\n",
    "- $ h $ is the step size,\n",
    "- $ \\mathbf{f}(t_{n+1}, \\mathbf{y}_{n+1}) $ is the vector of derivatives evaluated at the next time step $ t_{n+1} $.\n",
    "\n",
    "#### **Characteristics**\n",
    "\n",
    "- **Stability**: The Backward Euler method is more stable than the Forward Euler method, especially for stiff systems.\n",
    "- **Accuracy**: It is also a first-order method, meaning the error decreases linearly with the step size, but typically requires fewer steps for stability in challenging problems.\n",
    "- **Implicit Nature**: Unlike the explicit Forward Euler method, the Backward Euler method requires solving an equation at each time step, which can be computationally more expensive.\n",
    "\n",
    "The Backward Euler method is particularly useful for stiff systems, where it provides better stability than explicit methods, though it may require more computation due to its implicit nature. Below, we implement the Backward Euler method for systems in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def backward_euler(f, initial_state, t0, tf, dt, args):\n",
    "    def f_(t, state, args=args):\n",
    "        return f(t, state, *args)\n",
    "    t = np.arange(t0, tf, dt)\n",
    "    n = len(t)\n",
    "    states = np.zeros((n, len(initial_state)))\n",
    "    states[0] = initial_state\n",
    "    for i in range(n - 1):\n",
    "        t_next = t[i] + dt\n",
    "        state = states[i]\n",
    "        next_state = state\n",
    "        next_state = state + dt * f_(t_next, next_state)\n",
    "        states[i + 1] = next_state\n",
    "    return states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Runge-Kutta 2nd Order Method**\n",
    "\n",
    "The **Runge-Kutta 2nd order (RK2) method** is an explicit numerical technique used to solve systems of ordinary differential equations. It improves upon the Forward Euler method by considering both the current and predicted values to estimate the solution at the next time step, offering better accuracy.\n",
    "\n",
    "#### **Formula**\n",
    "\n",
    "Consider a system of differential equations of the form:\n",
    "\n",
    "$$ \\frac{d\\mathbf{y}}{dt} = \\mathbf{f}(t, \\mathbf{y}), \\quad \\mathbf{y}(t_0) = \\mathbf{y_0} $$\n",
    "\n",
    "The RK2 method approximates the solution for each component of the system as:\n",
    "\n",
    "$$ \\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\cdot \\mathbf{f}\\left(t_n + \\frac{h}{2}, \\mathbf{y}_n + \\frac{h}{2} \\cdot \\mathbf{f}(t_n, \\mathbf{y}_n)\\right) $$\n",
    "\n",
    "where:\n",
    "- $ \\mathbf{y}_n $ is the vector of solutions at the current step,\n",
    "- $ h $ is the step size,\n",
    "- $ \\mathbf{f}(t_n, \\mathbf{y}_n) $ is the vector of derivatives evaluated at $ t_n $,\n",
    "- $ \\mathbf{f}\\left(t_n + \\frac{h}{2}, \\mathbf{y}_n + \\frac{h}{2} \\cdot \\mathbf{f}(t_n, \\mathbf{y}_n)\\right) $ is the derivative evaluated at the intermediate point.\n",
    "\n",
    "#### **Characteristics**\n",
    "\n",
    "- **Improved Accuracy**: The RK2 method is more accurate than the Forward Euler method because it takes into account both the current state and an estimate of the future state.\n",
    "- **First-Order Accuracy**: While more accurate than Euler’s method, RK2 is still a second-order method, meaning the error decreases quadratically with the step size.\n",
    "- **Computational Cost**: The RK2 method requires more computations per step compared to Euler's methods, but it provides a good balance between accuracy and computational efficiency.\n",
    "\n",
    "The RK2 method is often used when a higher accuracy than the Forward Euler method is needed but without the increased complexity of higher-order methods like the classic Runge-Kutta 4th order method. Below, we implement the Runge-Kutta 2nd order method for systems in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RK2(f, initial_state, t0, tf, dt, args):\n",
    "    def f_(t,state, args=args):\n",
    "        return f(t, state, *args)\n",
    "    t = np.arange(t0, tf, dt)\n",
    "    n = len(t)\n",
    "    states = np.zeros((n, len(initial_state)))\n",
    "    states[0] = initial_state\n",
    "    for i in range(n - 1):\n",
    "        k1 = f_(t[i], states[i])\n",
    "        k2 = f_(t[i] + dt, states[i] + dt * k1)\n",
    "        states[i + 1] = states[i] + dt / 2 * (k1 + k2)\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Runge-Kutta 4th Order Method**\n",
    "\n",
    "The **Runge-Kutta 4th order (RK4) method** is one of the most widely used numerical techniques for solving systems of ordinary differential equations. It is an explicit method that provides high accuracy by considering multiple intermediate points within each time step to estimate the solution at the next time step.\n",
    "\n",
    "#### **Formula**\n",
    "\n",
    "Consider a system of differential equations of the form:\n",
    "\n",
    "$$ \\frac{d\\mathbf{y}}{dt} = \\mathbf{f}(t, \\mathbf{y}), \\quad \\mathbf{y}(t_0) = \\mathbf{y_0} $$\n",
    "\n",
    "The RK4 method approximates the solution for each component of the system as:\n",
    "\n",
    "$$ \\mathbf{y}_{n+1} = \\mathbf{y}_n + \\frac{h}{6} \\left( \\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4 \\right) $$\n",
    "\n",
    "where the intermediate slopes are computed as follows:\n",
    "\n",
    "- $ \\mathbf{k}_1 = h \\cdot \\mathbf{f}(t_n, \\mathbf{y}_n) $\n",
    "- $ \\mathbf{k}_2 = h \\cdot \\mathbf{f}\\left(t_n + \\frac{h}{2}, \\mathbf{y}_n + \\frac{\\mathbf{k}_1}{2}\\right) $\n",
    "- $ \\mathbf{k}_3 = h \\cdot \\mathbf{f}\\left(t_n + \\frac{h}{2}, \\mathbf{y}_n + \\frac{\\mathbf{k}_2}{2}\\right) $\n",
    "- $ \\mathbf{k}_4 = h \\cdot \\mathbf{f}(t_n + h, \\mathbf{y}_n + \\mathbf{k}_3) $\n",
    "\n",
    "where:\n",
    "- $ \\mathbf{y}_n $ is the vector of solutions at the current step,\n",
    "- $ h $ is the step size,\n",
    "- $ \\mathbf{k}_1, \\mathbf{k}_2, \\mathbf{k}_3, \\mathbf{k}_4 $ are the intermediate slopes used to estimate the next value.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Characteristics**\n",
    "\n",
    "- **High Accuracy**: The RK4 method is a fourth-order method, meaning the error decreases with the step size to the fourth power, offering significantly higher accuracy than lower-order methods.\n",
    "- **Computational Cost**: While RK4 provides excellent accuracy, it requires more computational effort per step compared to methods like Forward Euler or Runge-Kutta 2nd order, as it computes four intermediate slopes at each step.\n",
    "- **Stability**: The RK4 method strikes a balance between accuracy and stability, making it suitable for a wide range of problems, including non-stiff systems.\n",
    "\n",
    "The RK4 method is highly effective for solving systems of ordinary differential equations where high accuracy is needed. While it is computationally more expensive than simpler methods, it is widely used in practice due to its reliability and precision. Below, we implement the Runge-Kutta 4th order method for systems in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RK4(f, initial_state, t0, tf, dt, args):\n",
    "    def f_(t,state, args=args):\n",
    "        return f(t, state, *args)\n",
    "    t = np.arange(t0, tf, dt)\n",
    "    n = len(t)\n",
    "    states = np.zeros((n, len(initial_state)))\n",
    "    states[0] = initial_state\n",
    "    for i in range(n - 1):\n",
    "        state= states[i]\n",
    "        k1 = f_(t[i], state)\n",
    "        k2 = f_(t[i] + dt / 2, state + dt / 2 * k1)\n",
    "        k3 = f_(t[i] + dt / 2, state + dt / 2 * k2)\n",
    "        k4 = f_(t[i] + dt, state + dt * k3)\n",
    "        states[i + 1] = states[i] + dt / 6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    return states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a wrapper method that can be used to solve the Lorenz system using the Forward Euler, Backward Euler, RK2, and RK4 methods. The method takes the system of differential equations, initial conditions, parameters, time span, and step size as input and returns the solution trajectories for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def solve_ivp(f, t_span, initial_state, args, t_eval, *, method=\"RK4\"):\n",
    "    match method:\n",
    "        case \"RK4\":\n",
    "            method = RK4\n",
    "        case \"forward_euler\":\n",
    "            method = forward_euler\n",
    "        case \"backward_euler\":\n",
    "            method = backward_euler\n",
    "        case \"RK2\":\n",
    "            method = RK2\n",
    "        case _:\n",
    "            raise ValueError(f\"Method {method} not recognized\")\n",
    "    t0, tf = t_span \n",
    "    dt = t_eval[1] - t_eval[0]\n",
    "    return method(f, initial_state, t0, tf, dt, args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plotting the Lorenz Attractor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code we will use for all of our 3D plots. The library `plotly` is used for interactive 3D plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def plot_lorenz_attractor(\n",
    "    sigma: float = 10.0,\n",
    "    rho: float = 28.0,\n",
    "    beta: float = 8.0 / 3.0,\n",
    "    initial_state: np.ndarray = np.array([1.0, 0.0, 0.0]),\n",
    "    t_start: float = 0.0,\n",
    "    t_end: float =400.0,\n",
    "    plots: int = 1,\n",
    "    ERROR: float = 0.001,\n",
    "    cmap: str = \"GnBu\",\n",
    "    plot_thickness: int = 2,\n",
    "    color_offset: float = 0.1,\n",
    "    fig_size: tuple = (1350, 900),\n",
    "    method : str = \"RK4\"\n",
    "):\n",
    "    plots = int(plots)\n",
    "    if plots < 1:\n",
    "        raise ValueError(\"Number of plots must be at least 1\")\n",
    "\n",
    "    t_eval = np.linspace(t_start, t_end, 1000 * int(t_end - t_start))\n",
    "\n",
    "    fig = go.Figure()\n",
    "    color_values = np.linspace(color_offset, 1- color_offset, plots)\n",
    "\n",
    "    for plot_num in range(plots):\n",
    "        perturbed_state = initial_state * (1 + (ERROR * plot_num))  # Small perturbation\n",
    "\n",
    "        solution = solve_ivp(\n",
    "            lorenz,\n",
    "            [t_start, t_end],\n",
    "            perturbed_state,\n",
    "            args=(sigma, rho, beta),\n",
    "            t_eval=t_eval,\n",
    "            method=method\n",
    "        )\n",
    "        color_value = 0.5 if plots==1 else color_values[plot_num]  # Map plot_num to a value between 0 and 1\n",
    "\n",
    "        # Get the corresponding color from the colorscale\n",
    "        color = px.colors.sample_colorscale(cmap, [color_value])[0]\n",
    "\n",
    "        x, y, z = solution.T\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                z=z,\n",
    "                mode=\"lines\",\n",
    "                line=dict(\n",
    "                    color=color,\n",
    "                    width=plot_thickness,\n",
    "                ),\n",
    "                name=f\"Initial Condition {plot_num + 1}\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_traces(opacity=0.4)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=(\n",
    "            f\"Lorenz Attractor - Two Initial Conditions (ERROR:{ERROR*100}%)\"\n",
    "            if plots > 1\n",
    "            else \"Lorenz Attractor - One Initial Condition\"\n",
    "        ),\n",
    "        scene=dict(\n",
    "            xaxis=dict(\n",
    "                backgroundcolor=\"black\",\n",
    "                gridcolor=\"white\",\n",
    "                showbackground=True,\n",
    "                zerolinecolor=\"white\",\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                backgroundcolor=\"black\",\n",
    "                gridcolor=\"white\",\n",
    "                showbackground=True,\n",
    "                zerolinecolor=\"white\",\n",
    "            ),\n",
    "            zaxis=dict(\n",
    "                backgroundcolor=\"black\",\n",
    "                gridcolor=\"white\",\n",
    "                showbackground=True,\n",
    "                zerolinecolor=\"white\",\n",
    "            ),\n",
    "            camera=dict(\n",
    "                up=dict(x=0, y=0, z=1),\n",
    "                center=dict(x=0, y=0, z=0),\n",
    "                eye=dict(x=2.5, y=0.1, z=0.1),\n",
    "            ),\n",
    "        ),\n",
    "        margin=dict(r=10, l=10, b=10, t=10),\n",
    "        paper_bgcolor=\"black\",\n",
    "        plot_bgcolor=\"black\",\n",
    "        width=fig_size[0],\n",
    "        height=fig_size[1],\n",
    "        font=dict(color=\"white\"),\n",
    "        showlegend=True,\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To run the plots change the variable `run` to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    plot_lorenz_attractor(plots=1, plot_thickness=5, cmap='Tealgrn', fig_size=(900, 900), method=\"forward_euler\", t_end=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    plot_lorenz_attractor(plots=1, plot_thickness=5, cmap='Tealgrn', fig_size=(900, 900), method=\"backward_euler\", t_end=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    plot_lorenz_attractor(plots=1, plot_thickness=5, cmap='Tealgrn', fig_size=(900, 900), method=\"RK2\", t_end=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    plot_lorenz_attractor(plots=1, plot_thickness=5, cmap='Tealgrn', fig_size=(900, 900), method=\"RK4\", t_end=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if run:\n",
    "#     plot_lorenz_attractor(plots=2, plot_thickness=1.7, cmap='Plasma', color_offset=0.2, fig_size=(900, 900))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Observation**\n",
    "We can quite clearly see that although the error was not significant at all (a mere 0.1%), it nonetheless had a substantial effect on the behavior and evolution of the system. This is a key feature of deterministic chaotic systems: the smallest changes in initial conditions lead to dramatically different outcomes. The 'deterministic' part means that although the system seems to exhibit random and aperiodic behavior, the path that the system will take, given the same initial conditions, will always stay the same.\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _**Animation**_\n",
    "\n",
    "The animation below vividly illustrates the incredible sensitivity of chaotic systems to initial conditions, a concept often referred to as the **butterfly effect**. In this system, even the slightest difference in the starting points—trajectories that are almost indistinguishable at first—quickly spiral into wildly different outcomes. This is the hallmark of chaotic dynamics, where **tiny changes** in the initial conditions can lead to **vastly divergent** paths, making long-term predictions practically impossible.\n",
    "\n",
    "- The **Red** trajectory begins at $ P_0 = \\hat{i} $, a simple starting point along the x-axis.\n",
    "- The **Orange** trajectory starts from a point **slightly off**, at $ P_1 = \\hat{i} + 0.01\\hat{j} $, deviating ever so slightly in the y-direction.\n",
    "- The **Blue** trajectory takes yet another subtle departure from the initial condition, starting at $ P_2 = \\hat{i} + 0.01\\hat{k} $, with a minuscule change in the z-direction.\n",
    "\n",
    "These three trajectories begin their journeys only 0.01 units apart, yet within mere moments, they start to separate drastically. Despite their initial closeness, the system's chaotic nature causes the paths to diverge rapidly and unpredictably. By the end of the $40$-second simulation, these trajectories occupy entirely different regions of the phase space, illustrating the **unpredictable** and **nonlinear** behavior inherent to chaotic systems.\n",
    "\n",
    "This phenomenon—where small, almost imperceptible differences lead to entirely different futures—is one of the most fascinating and unsettling features of chaotic dynamics. It underscores the limits of our ability to predict the future, even with nearly identical starting conditions. The butterfly effect reminds us that in chaotic systems, **even the smallest perturbation can trigger profound changes**, making the system’s future behavior all but impossible to forecast.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video width=\"1000\" height=\"600\" controls>\n",
    "  <source src=\"LorenzAttractor.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Observation**\n",
    "\n",
    "One more observation we can derive form this animation is that the system diverges faster in the $z$-direction than in the $x$ or $y$ directions. This is due to the nature of the Lorenz system, where the $z$-variable is more sensitive to changes in the initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that genrated the animation\n",
    "\n",
    "from manim import *\n",
    "import numpy as np\n",
    "\n",
    "def lorenz(t, state, sigma, rho, beta):\n",
    "    x, y, z = state\n",
    "    dxdt = sigma * (y - x)\n",
    "    dydt = x * (rho - z) - y\n",
    "    dzdt = x * y - beta * z\n",
    "    return np.array([dxdt, dydt, dzdt])\n",
    "\n",
    "def RK4(f, initial_state, t0, tf, dt, args):\n",
    "    def f_(t,state, args=args):\n",
    "        return f(t, state, *args)\n",
    "    t = np.arange(t0, tf, dt)\n",
    "    n = len(t)\n",
    "    states = np.zeros((n, len(initial_state)))\n",
    "    states[0] = initial_state\n",
    "    for i in range(n - 1):\n",
    "        state= states[i]\n",
    "        k1 = f_(t[i], state)\n",
    "        k2 = f_(t[i] + dt / 2, state + dt / 2 * k1)\n",
    "        k3 = f_(t[i] + dt / 2, state + dt / 2 * k2)\n",
    "        k4 = f_(t[i] + dt, state + dt * k3)\n",
    "        states[i + 1] = states[i] + dt / 6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    return states\n",
    "\n",
    "def solve_ivp(f, t_span, initial_state, args, t_eval, *, method=\"RK4\"):\n",
    "    match method:\n",
    "        case \"RK4\":\n",
    "            method = RK4\n",
    "        case \"forward_euler\":\n",
    "            method = forward_euler\n",
    "        case \"backward_euler\":\n",
    "            method = backward_euler\n",
    "        case \"RK2\":\n",
    "            method = RK2\n",
    "        case _:\n",
    "            raise ValueError(f\"Method {method} not recognized\")\n",
    "    t0, tf = t_span \n",
    "    dt = t_eval[1] - t_eval[0]\n",
    "    return method(f, initial_state, t0, tf, dt, args)\n",
    "\n",
    "class LorenzAttractor(ThreeDScene):\n",
    "    def construct(self):\n",
    "        # Lorenz system parameters\n",
    "        sigma = 10\n",
    "        rho = 28\n",
    "        beta = 8 / 3\n",
    "        initial_states = np.array([[1, 0, 0],\n",
    "                                   [1, 0.01, 0],\n",
    "                                   [1, 0, 0.01]])\n",
    "\n",
    "        # Create the 3D axes with wider ranges\n",
    "        axes = ThreeDAxes(\n",
    "            x_range=[-1, 1, 0.5],\n",
    "            y_range=[-1, 1, 0.5],\n",
    "            z_range=[-1, 1, 0.5]\n",
    "            )\n",
    "        \n",
    "        t0, tf = 0, 40\n",
    "        t_eval = np.linspace(t0, tf, (tf - t0) * 100)\n",
    "        t_span = [t0, tf]\n",
    "        curves = VGroup()\n",
    "        # Iterate over initial states to create 3 curves\n",
    "        for initial_state, color in zip(initial_states, [RED, ORANGE, BLUE]):\n",
    "            # Solve the system using RK4\n",
    "            states = solve_ivp(lorenz, t_span, initial_state, args=(sigma, rho, beta), t_eval=t_eval)\n",
    "            states = states / 50\n",
    "            \n",
    "            # Convert the states to 3D points\n",
    "            curve = [axes.c2p(x, y, z) for x, y, z in states]\n",
    "            curve_obj = VMobject(stroke_width=2, stroke_opacity=0.4, color=color).set_points_smoothly(curve).set_color(color)\n",
    "            curves.add(curve_obj)\n",
    "            \n",
    "        dots = VGroup(\n",
    "            *(Dot3D(color=color) for color in [RED, ORANGE, BLUE])\n",
    "        )\n",
    "        \n",
    "        def update_dots(dots):\n",
    "            for dot, curve_obj in zip(dots, curves):\n",
    "                dot.move_to(curve_obj.get_end())\n",
    "           \n",
    "        dots.add_updater(update_dots)\n",
    "        \n",
    "        # Set up camera angle\n",
    "\n",
    "        self.wait(1)\n",
    "        self.set_camera_orientation(phi=75 * DEGREES, theta=-30 * DEGREES)\n",
    "\n",
    "        # Add the axes and curves to the scene\n",
    "        self.add(axes, dots)\n",
    "        self.play(\n",
    "            \n",
    "            *[Create(curve_obj, rate_func=linear) for curve_obj in curves],\n",
    "            run_time=tf - t0\n",
    "        )\n",
    "        # Begin ambient camera rotation to visualize the attractor from different angles\n",
    "        self.begin_ambient_camera_rotation(rate=0.2)\n",
    "\n",
    "        # # Wait for a few seconds at the end to view the final attractor\n",
    "        self.wait(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this code in a file script.py we can run the following command to generate the video LorenzAttractor.mp4:\n",
    "```bash\n",
    "manim -pqh script.py LorenzAttractor\n",
    "```\n",
    "The `-pqh` flag is used to render the video in a higher quality. For lower quality and faster rendering, use the `-pql` flag.\n",
    "\n",
    "For instalation of the `manim` library, please refer to the official documentation: https://docs.manim.community/en/stable/installation.html.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
